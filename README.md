# SpiderCrawl

A web spider framework that can crawl a domain and let you have information about the pages it visits. This includes title, links, css, words, etc. You can also customize what you want to do before & after each fetch request from the target url, and many many more!

Long story short - Feed an URL to SpiderCrawl and it will crawl + scrape the content for you. 

## Installation

Add this line to your application's Gemfile:

```ruby
gem 'spidercrawl'
```

And then execute:

    $ bundle

Or install it yourself as:

    $ gem install spidercrawl

## Usage

TODO: Write usage instructions here

## Contributing

1. Fork it ( https://github.com/belsonheng/spidercrawl/fork )
2. Create your feature branch (`git checkout -b my-new-feature`)
3. Commit your changes (`git commit -am 'Add some feature'`)
4. Push to the branch (`git push origin my-new-feature`)
5. Create a new Pull Request

## License

SpiderCrawl is released under the [MIT license](https://github.com/belsonheng/spidercrawl/blob/master/LICENSE.txt).
